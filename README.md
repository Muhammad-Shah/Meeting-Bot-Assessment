# Meeting Bot Assessment

A comprehensive meeting transcript analysis application that allows users to upload meeting transcripts and chat with an AI assistant about the contents. Built with FastAPI and advanced AI capabilities using LangChain and OpenAI GPT-4.

## üèóÔ∏è Project Structure

```
meeting-bot/
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ index.html                # Chat UI and transcript upload interface
‚îÇ   ‚îú‚îÄ‚îÄ script.js                 # Handles sending chat messages and uploads
‚îÇ   ‚îî‚îÄ‚îÄ style.css                 # Professional UI styling
‚îú‚îÄ‚îÄ chatbot/
‚îÇ   ‚îî‚îÄ‚îÄ engine.py                 # Advanced AI chatbot engine with LangChain
‚îú‚îÄ‚îÄ server.py                     # FastAPI server with `/chat` and `/upload` endpoints
‚îú‚îÄ‚îÄ .devcontainer/                # VS Code Dev Container configuration
‚îú‚îÄ‚îÄ Dockerfile                    # Python 3 + FastAPI environment
‚îú‚îÄ‚îÄ requirements.txt              # FastAPI, LangChain, and AI dependencies
‚îî‚îÄ‚îÄ README.md                     # This file
```

## üöÄ Quick Start

### Option 1: Using VS Code Dev Container (Recommended) - Zero Setup!

**Prerequisites**: 
- [Docker](https://www.docker.com/get-started) installed
- [VS Code](https://code.visualstudio.com/) with [Remote Development Extension Pack](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack)

**Setup Steps (30 seconds)**:

1. **Open in VS Code**
   ```bash
   code meeting-bot  # Or File > Open Folder in VS Code
   ```

2. **Reopen in Container**
   - VS Code will show: "Folder contains a Dev Container configuration file. Reopen folder to develop in a container"
   - Click **"Reopen in Container"**
   - Alternative: Press `F1` ‚Üí "Remote-Containers: Reopen in Container"

3. **Wait for automatic setup** (first time only)
   - Docker builds the development environment
   - All dependencies install automatically
   - VS Code extensions configure automatically

4. **Start both frontend and backend**
   ```bash
   ./start-dev.sh
   ```

5. **Access the application**
   - Frontend: http://localhost:5000/
   - Backend API: http://localhost:5000

**That's it! üéâ Ready to code your AI engine.**

**Devcontainer Features**:
- ‚úÖ Python 3.11 + FastAPI pre-installed
- ‚úÖ VS Code extensions (Python, Copilot, Git tools)
- ‚úÖ Zero manual dependency installation


### Option 2: Local Development

```bash
# Install dependencies
pip install -r requirements.txt

# Start the server
python server.py

# Open frontend/index.html in your browser with live server
```

## ‚ú® Features Implemented

### ü§ñ Advanced AI Engine

‚úÖ **Intelligent Intent Classification**: Automatically routes user queries to appropriate handlers  
‚úÖ **Comprehensive Transcript Analysis**: Uses GPT-4 for deep meeting understanding  
‚úÖ **Context-Aware Responses**: Maintains conversation history for better interactions  
‚úÖ **Professional Summarization**: Multi-level summarization with key insights extraction  
‚úÖ **Question-Answering System**: Precise answers based on transcript content  

### üèóÔ∏è Technical Architecture

‚úÖ **FastAPI Backend**: High-performance async API with automatic OpenAPI documentation  
‚úÖ **LangChain Integration**: Advanced prompt engineering and chain management  
‚úÖ **Session Management**: In-memory storage with unique session identifiers  
‚úÖ **Error Handling**: Comprehensive error handling and logging  
‚úÖ **Professional Frontend**: Clean, responsive UI with real-time chat interface  

### üéØ Core Capabilities

- **Meeting Summarization**: Extract main topics, decisions, action items, and participants
- **Smart Q&A**: Answer specific questions about meeting content with context
- **Intent Recognition**: Automatically understand user intent (summarize, question, chat)
- **Conversation Context**: Maintain chat history for coherent multi-turn conversations
- **Long Transcript Handling**: Intelligent chunking for large meeting transcripts

### Sample Interactions

```
User: "What were the main topics discussed?"
Bot: [Analyze transcript and list key topics]

User: "What action items were assigned?"
Bot: [Extract and list action items with assignees]

User: "Who participated in this meeting?"
Bot: [Identify and list participants]

User: "Summarize the key decisions made"
Bot: [Provide summary of decisions]
```


**Add your dependencies** to `requirements.txt` as needed.

## üîß System Architecture

```
[Frontend] ‚îÄ‚îÄHTTP‚îÄ‚îÄ> [FastAPI Server] ‚îÄ‚îÄPython‚îÄ‚îÄ> [LangChain AI Engine]
    ‚îÇ                      ‚îÇ                         ‚îÇ
    ‚îÇ                      ‚îÇ                         ‚îÇ
    ‚îî‚îÄ‚îÄ Chat UI            ‚îî‚îÄ‚îÄ Session Management    ‚îî‚îÄ‚îÄ Intent Classification
        Upload Interface       Memory Storage            ‚îú‚îÄ‚îÄ Summarization
                                                        ‚îú‚îÄ‚îÄ Question Answering
                                                        ‚îî‚îÄ‚îÄ General Chat
```
![Architecture](./architecture.png)

### AI Engine Components

```
MeetingBotEngine
‚îú‚îÄ‚îÄ PromptRouter           # Intent classification
‚îú‚îÄ‚îÄ TranscriptSummarizer   # Meeting summarization
‚îú‚îÄ‚îÄ QuestionAnswering      # Context-aware Q&A
‚îî‚îÄ‚îÄ ChatHistoryManager     # Conversation memory
```

### API Endpoints

- **POST `/upload`**: Upload meeting transcript
  ```json
  {
    "transcript": "Meeting transcript text...",
    "session_id": "session_abc123"
  }
  ```

- **POST `/chat`**: Send chat message
  ```json
  {
    "message": "What were the action items?",
    "session_id": "session_abc123"
  }
  ```

### Session Data Structure

```python
session_data = {
    'transcript': 'Full meeting transcript text',
    'chat_history': [
        {'sender': 'user', 'content': 'User message'},
        {'sender': 'bot', 'content': 'Bot response'}
    ],
    'session_id': 'unique_session_identifier'
}
```

## üõ†Ô∏è Technical Implementation

### Dependencies

```
fastapi>=0.104.1          # Modern, fast web framework
uvicorn>=0.24.0           # ASGI server for FastAPI
langchain>=0.1.0          # AI/ML framework for building applications
langchain-openai>=0.0.2   # OpenAI integration for LangChain
langchain-mongodb>=0.1.0  # MongoDB integration for chat history
pydantic>=2.5.0           # Data validation and settings management
python-dotenv>=1.0.0      # Environment variable management
```

### Environment Variables

Create a `.env` file in the project root:

```env
OPENAI_API_KEY=your_openai_api_key_here
MONGODB_CONNECTION_STRING=mongodb://localhost:27017/  # Optional
DEBUG=True  # Optional, for development
```

## üöÄ Getting Started

### Prerequisites

1. **Python 3.8+** installed
2. **OpenAI API Key** - Get one from [OpenAI Platform](https://platform.openai.com/api-keys)
3. **Node.js** (for frontend development server) - Optional

### Installation & Setup

1. **Clone the repository**
   ```bash
   git clone <repository-url>
   cd meeting-bot-assessment
   ```

2. **Install Python dependencies**
   ```bash
   pip install -r requirements.txt
   ```

3. **Set up environment variables**
   ```bash
   # Create .env file
   echo "OPENAI_API_KEY=your_api_key_here" > .env
   ```

4. **Start the FastAPI server**
   ```bash
   python server.py
   ```

## üîç Testing the Application

1. **Access the application**: http://localhost:5000 (or open index.html)
2. **Upload a sample transcript** in the upload section
3. **Test various interactions**:
   - "Summarize this meeting"
   - "What action items were discussed?"
   - "Who were the key participants?"
   - "What decisions were made?"
   - "Can you clarify the main outcomes?"

## üìã Sample Meeting Transcript

```
Meeting: Q4 Planning Session
Date: 2024-01-15
Attendees: Sarah (Product Manager), Mike (Engineer), Lisa (Designer)

Sarah: Let's discuss our Q4 roadmap. We need to prioritize the new user dashboard.
Mike: I can start working on the backend APIs. Should take about 3 weeks.
Lisa: I'll handle the UI mockups. Can have them ready by Friday.
Sarah: Great. Mike, can you also look into the performance issues we discussed?
Mike: Absolutely. I'll investigate the database queries this week.
Lisa: Should we schedule a design review for next Tuesday?
Sarah: Yes, let's do that. I'll send out calendar invites.

Action Items:
- Mike: Develop backend APIs (3 weeks)
- Lisa: Create UI mockups (by Friday)
- Mike: Investigate database performance (this week)
- Sarah: Schedule design review for next Tuesday
```

## üéØ Key Features Explained

### Intent Classification
The system automatically classifies user messages into four categories:
- **Summarize**: User wants a meeting summary
- **Question-Answer**: Specific questions about meeting content
- **General Chat**: Casual conversation
- **Clarification**: Follow-up questions about previous responses

### Advanced Summarization
- **Structured Output**: Main topics, decisions, action items, participants
- **Long Transcript Handling**: Automatic chunking for large transcripts
- **Context Preservation**: Maintains meeting context across chunks

### Smart Question Answering
- **Context-Aware**: Uses chat history for better understanding
- **Source-Based**: Answers only from transcript content
- **Precise Responses**: Direct quotes and specific references

### Error Handling
- **Graceful Degradation**: Handles API failures and edge cases
- **User-Friendly Messages**: Clear error communication
- **Logging**: Comprehensive logging for debugging

## üìä API Documentation

When the server is running, visit http://localhost:5000/docs for interactive API documentation (automatically generated by FastAPI).

### Available Endpoints

- **GET `/health`**: Health check endpoint
- **POST `/upload`**: Upload meeting transcript
- **POST `/chat`**: Send chat message

## ü§ù Troubleshooting

### Common Issues

1. **"OpenAI API key not set" error**
   - Ensure `.env` file exists with `OPENAI_API_KEY=your_key`
   - Check that the `.env` file is in the project root directory

2. **"Session not found" error**
   - Upload a transcript before trying to chat
   - Check that session IDs match between upload and chat

3. **CORS errors in browser**
   - Ensure the server is running on localhost:5000
   - Check that frontend is accessing the correct API URL

4. **Long response times**
   - Large transcripts take more time to process
   - GPT-4 API calls can be slower than GPT-3.5

### Performance Optimization

- **Caching**: Engine initialization could be cached for better performance
- **Streaming**: Consider implementing streaming responses for long operations
- **Model Selection**: Switch to `gpt-3.5-turbo` for faster responses

---

## üèÜ Project Highlights

This implementation demonstrates:
- ‚úÖ **Modern FastAPI Architecture**
- ‚úÖ **Advanced LangChain Integration**
- ‚úÖ **Professional Error Handling**
- ‚úÖ **Scalable AI Engine Design**
- ‚úÖ **Clean, Maintainable Code**
- ‚úÖ **Comprehensive Documentation**

**The Meeting Bot is ready for production use!** üöÄ